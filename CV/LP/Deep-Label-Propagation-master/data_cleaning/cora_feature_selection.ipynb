{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# node_dir  = 'Pubmed-Diabetes/data/nodes_selected.csv'\n",
    "# all_node_dir  = 'Pubmed-Diabetes/data/nodes.csv'\n",
    "# edge_dir  = 'Pubmed-Diabetes/data/edges.csv'\n",
    "# graph_dir = 'Pubmed-Diabetes/data/graph.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contents = pd.read_csv('../cora/content.csv',delimiter=',')\n",
    "cites    = pd.read_csv('../cora/cites.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_id(el):\n",
    "    return np.where(contents['id'] == el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjanecy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "G.add_edges_from(cites[['source_new','target_new']].values)\n",
    "G2 = G.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gc = max(nx.connected_component_subgraphs(G2), key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(Gc,nodelist=contents.index)\n",
    "A = np.array(A.todense())\n",
    "non_zeros = np.where(np.all(A == 0, axis=1) == False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = A[~np.all(A == 0, axis=1),:]\n",
    "A = A[:,~np.all(A == 0, axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 2485)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('../cora/graph.csv',A,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2707"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(non_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contents = contents.iloc[non_zeros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature1427</th>\n",
       "      <th>feature1428</th>\n",
       "      <th>feature1429</th>\n",
       "      <th>feature1430</th>\n",
       "      <th>feature1431</th>\n",
       "      <th>feature1432</th>\n",
       "      <th>feature1433</th>\n",
       "      <th>label</th>\n",
       "      <th>is_nn</th>\n",
       "      <th>num_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1061127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rule_Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1106406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1126012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1107140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1102850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1106418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1123188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1128990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>109323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>217139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Case_Based</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1126029</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1118017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>49482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>753265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>249858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1113739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>48766</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>646195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1126050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>59626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>340299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>354004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>242637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1106492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rule_Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>1385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>254923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>34961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>46547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>13136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>1131137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>233106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>561613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>1131149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>1104258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>1152991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>447250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>102879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>1131150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>56708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>1128943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>134060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>102884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>4274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Case_Based</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>1131172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>767763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>152226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>152227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>1131180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>1128974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>1128975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>1128977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>1128978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>117328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Case_Based</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>24043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows Ã— 1437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0       31336         0         0         0         0         0         0   \n",
       "1     1061127         0         0         0         0         0         0   \n",
       "2     1106406         0         0         0         0         0         0   \n",
       "3       13195         0         0         0         0         0         0   \n",
       "4       37879         0         0         0         0         0         0   \n",
       "5     1126012         0         0         0         0         0         0   \n",
       "6     1107140         0         0         0         0         0         0   \n",
       "7     1102850         0         0         0         1         0         0   \n",
       "8       31349         0         0         0         0         0         0   \n",
       "9     1106418         0         0         0         0         0         0   \n",
       "10    1123188         0         0         0         0         0         0   \n",
       "11    1128990         0         0         0         0         0         0   \n",
       "12     109323         0         0         1         0         0         0   \n",
       "13     217139         0         0         0         0         0         0   \n",
       "14      31353         0         0         0         0         0         0   \n",
       "15      32083         0         0         0         0         0         0   \n",
       "16    1126029         0         0         0         0         0         0   \n",
       "17    1118017         0         0         0         0         0         0   \n",
       "18      49482         0         0         0         0         0         0   \n",
       "19     753265         0         0         0         0         0         0   \n",
       "20     249858         0         0         0         0         0         0   \n",
       "21    1113739         0         0         0         0         0         0   \n",
       "22      48766         0         0         0         0         0         0   \n",
       "23     646195         0         0         0         0         0         0   \n",
       "24    1126050         0         0         0         1         0         0   \n",
       "25      59626         0         0         0         0         0         0   \n",
       "26     340299         0         0         0         0         0         0   \n",
       "27     354004         0         0         0         0         0         0   \n",
       "28     242637         0         0         0         0         0         0   \n",
       "29    1106492         0         0         0         0         0         0   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "2672     1385         0         0         0         0         0         0   \n",
       "2673   254923         0         0         0         0         0         0   \n",
       "2674    34961         0         0         0         0         0         0   \n",
       "2675    46547         0         0         0         0         0         0   \n",
       "2676    13136         0         0         0         0         0         0   \n",
       "2677  1131137         0         0         0         0         0         0   \n",
       "2678   233106         0         0         0         0         0         0   \n",
       "2679   561613         0         0         0         0         0         0   \n",
       "2680  1131149         0         0         0         0         0         0   \n",
       "2681  1104258         0         0         0         0         0         0   \n",
       "2682  1152991         0         0         0         0         0         0   \n",
       "2683   447250         0         0         0         0         0         0   \n",
       "2685   102879         0         0         0         0         0         0   \n",
       "2686  1131150         0         0         0         0         0         0   \n",
       "2687    56708         0         0         0         0         0         0   \n",
       "2688  1128943         0         0         0         0         0         0   \n",
       "2689   134060         0         0         0         0         0         0   \n",
       "2690   102884         0         0         0         0         0         0   \n",
       "2692     4274         0         0         0         0         0         0   \n",
       "2693  1131172         0         0         0         0         0         0   \n",
       "2694   767763         0         0         0         0         0         0   \n",
       "2695   152226         0         0         0         0         0         0   \n",
       "2696   152227         0         0         0         0         0         0   \n",
       "2699  1131180         0         0         0         0         0         0   \n",
       "2702  1128974         0         0         0         0         0         0   \n",
       "2703  1128975         0         0         0         0         0         0   \n",
       "2704  1128977         0         0         0         0         0         0   \n",
       "2705  1128978         0         0         0         0         0         0   \n",
       "2706   117328         0         0         0         0         1         0   \n",
       "2707    24043         0         0         0         0         0         0   \n",
       "\n",
       "      feature7  feature8  feature9     ...      feature1427  feature1428  \\\n",
       "0            0         0         0     ...                1            0   \n",
       "1            0         0         0     ...                0            0   \n",
       "2            0         0         0     ...                0            0   \n",
       "3            0         0         0     ...                0            0   \n",
       "4            0         0         0     ...                0            0   \n",
       "5            0         0         0     ...                1            0   \n",
       "6            0         0         0     ...                0            0   \n",
       "7            0         0         0     ...                0            0   \n",
       "8            0         0         0     ...                0            0   \n",
       "9            0         0         0     ...                0            0   \n",
       "10           0         0         0     ...                0            0   \n",
       "11           0         0         0     ...                1            0   \n",
       "12           0         0         0     ...                0            0   \n",
       "13           0         0         0     ...                0            0   \n",
       "14           0         0         0     ...                0            0   \n",
       "15           0         0         0     ...                0            0   \n",
       "16           0         0         0     ...                0            0   \n",
       "17           0         0         0     ...                0            0   \n",
       "18           0         0         0     ...                0            0   \n",
       "19           0         0         0     ...                0            0   \n",
       "20           0         0         0     ...                0            1   \n",
       "21           0         0         0     ...                0            0   \n",
       "22           0         0         0     ...                0            0   \n",
       "23           0         0         0     ...                0            0   \n",
       "24           0         0         0     ...                0            0   \n",
       "25           0         0         0     ...                0            0   \n",
       "26           0         0         0     ...                0            0   \n",
       "27           0         0         0     ...                0            0   \n",
       "28           0         0         0     ...                0            0   \n",
       "29           0         0         0     ...                0            0   \n",
       "...        ...       ...       ...     ...              ...          ...   \n",
       "2672         0         0         0     ...                0            0   \n",
       "2673         0         0         0     ...                0            0   \n",
       "2674         0         0         0     ...                0            0   \n",
       "2675         0         0         0     ...                0            0   \n",
       "2676         0         0         0     ...                0            0   \n",
       "2677         0         0         0     ...                0            0   \n",
       "2678         0         0         0     ...                0            0   \n",
       "2679         0         0         0     ...                0            0   \n",
       "2680         0         0         0     ...                0            0   \n",
       "2681         0         0         0     ...                0            0   \n",
       "2682         0         0         0     ...                0            0   \n",
       "2683         0         0         0     ...                0            0   \n",
       "2685         0         0         0     ...                0            0   \n",
       "2686         0         0         0     ...                0            0   \n",
       "2687         0         0         0     ...                0            0   \n",
       "2688         0         0         0     ...                0            0   \n",
       "2689         0         0         0     ...                0            0   \n",
       "2690         0         0         0     ...                0            0   \n",
       "2692         0         0         0     ...                0            0   \n",
       "2693         0         0         0     ...                0            0   \n",
       "2694         0         0         0     ...                1            0   \n",
       "2695         0         0         0     ...                0            0   \n",
       "2696         0         0         0     ...                0            0   \n",
       "2699         0         0         0     ...                0            0   \n",
       "2702         1         0         0     ...                0            0   \n",
       "2703         0         0         0     ...                0            0   \n",
       "2704         0         0         0     ...                0            0   \n",
       "2705         0         0         0     ...                0            0   \n",
       "2706         0         0         0     ...                0            0   \n",
       "2707         0         0         0     ...                0            0   \n",
       "\n",
       "      feature1429  feature1430  feature1431  feature1432  feature1433  \\\n",
       "0               0            0            0            0            0   \n",
       "1               0            0            0            0            0   \n",
       "2               0            0            0            0            0   \n",
       "3               0            0            0            0            0   \n",
       "4               0            0            0            0            0   \n",
       "5               0            0            0            0            0   \n",
       "6               0            0            0            0            0   \n",
       "7               0            0            0            0            0   \n",
       "8               0            0            0            0            0   \n",
       "9               0            0            0            0            0   \n",
       "10              0            0            0            0            0   \n",
       "11              0            0            0            0            0   \n",
       "12              0            0            0            0            0   \n",
       "13              0            0            0            0            0   \n",
       "14              0            0            0            0            0   \n",
       "15              0            0            0            0            0   \n",
       "16              0            0            0            0            0   \n",
       "17              0            0            0            0            0   \n",
       "18              0            0            0            0            0   \n",
       "19              0            0            0            0            0   \n",
       "20              0            0            0            0            0   \n",
       "21              0            0            0            0            0   \n",
       "22              0            0            0            0            0   \n",
       "23              0            0            0            0            0   \n",
       "24              0            0            0            0            0   \n",
       "25              0            0            0            0            0   \n",
       "26              0            0            0            1            0   \n",
       "27              0            0            0            0            0   \n",
       "28              0            0            0            0            0   \n",
       "29              0            0            0            0            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "2672            0            0            0            0            0   \n",
       "2673            0            0            0            0            0   \n",
       "2674            0            0            0            0            0   \n",
       "2675            0            0            0            0            0   \n",
       "2676            0            0            0            0            0   \n",
       "2677            0            0            0            0            0   \n",
       "2678            0            0            0            0            0   \n",
       "2679            0            0            0            0            0   \n",
       "2680            0            0            0            0            0   \n",
       "2681            0            0            0            0            0   \n",
       "2682            0            0            0            0            0   \n",
       "2683            0            0            0            0            0   \n",
       "2685            0            0            0            0            0   \n",
       "2686            0            0            0            0            0   \n",
       "2687            0            0            0            0            0   \n",
       "2688            0            0            0            0            0   \n",
       "2689            0            0            0            0            0   \n",
       "2690            0            0            0            0            0   \n",
       "2692            0            0            0            0            0   \n",
       "2693            0            0            0            0            0   \n",
       "2694            0            0            0            0            0   \n",
       "2695            0            0            0            0            0   \n",
       "2696            0            0            0            0            0   \n",
       "2699            0            0            0            0            0   \n",
       "2702            0            0            0            0            0   \n",
       "2703            0            0            0            0            0   \n",
       "2704            0            0            0            0            0   \n",
       "2705            0            0            0            0            0   \n",
       "2706            0            0            0            0            0   \n",
       "2707            0            0            0            0            0   \n",
       "\n",
       "                       label  is_nn  num_labels  \n",
       "0            Neural_Networks   True           0  \n",
       "1              Rule_Learning  False           1  \n",
       "2     Reinforcement_Learning  False           2  \n",
       "3     Reinforcement_Learning  False           2  \n",
       "4      Probabilistic_Methods  False           3  \n",
       "5      Probabilistic_Methods  False           3  \n",
       "6                     Theory  False           4  \n",
       "7            Neural_Networks   True           0  \n",
       "8            Neural_Networks   True           0  \n",
       "9                     Theory  False           4  \n",
       "10           Neural_Networks   True           0  \n",
       "11        Genetic_Algorithms  False           5  \n",
       "12     Probabilistic_Methods  False           3  \n",
       "13                Case_Based  False           6  \n",
       "14           Neural_Networks   True           0  \n",
       "15           Neural_Networks   True           0  \n",
       "16    Reinforcement_Learning  False           2  \n",
       "17           Neural_Networks   True           0  \n",
       "18           Neural_Networks   True           0  \n",
       "19           Neural_Networks   True           0  \n",
       "20                    Theory  False           4  \n",
       "21    Reinforcement_Learning  False           2  \n",
       "22        Genetic_Algorithms  False           5  \n",
       "23     Probabilistic_Methods  False           3  \n",
       "24    Reinforcement_Learning  False           2  \n",
       "25                    Theory  False           4  \n",
       "26           Neural_Networks   True           0  \n",
       "27     Probabilistic_Methods  False           3  \n",
       "28           Neural_Networks   True           0  \n",
       "29             Rule_Learning  False           1  \n",
       "...                      ...    ...         ...  \n",
       "2672         Neural_Networks   True           0  \n",
       "2673      Genetic_Algorithms  False           5  \n",
       "2674         Neural_Networks   True           0  \n",
       "2675                  Theory  False           4  \n",
       "2676         Neural_Networks   True           0  \n",
       "2677   Probabilistic_Methods  False           3  \n",
       "2678         Neural_Networks   True           0  \n",
       "2679   Probabilistic_Methods  False           3  \n",
       "2680         Neural_Networks   True           0  \n",
       "2681         Neural_Networks   True           0  \n",
       "2682   Probabilistic_Methods  False           3  \n",
       "2683         Neural_Networks   True           0  \n",
       "2685                  Theory  False           4  \n",
       "2686         Neural_Networks   True           0  \n",
       "2687  Reinforcement_Learning  False           2  \n",
       "2688      Genetic_Algorithms  False           5  \n",
       "2689                  Theory  False           4  \n",
       "2690                  Theory  False           4  \n",
       "2692              Case_Based  False           6  \n",
       "2693   Probabilistic_Methods  False           3  \n",
       "2694                  Theory  False           4  \n",
       "2695                  Theory  False           4  \n",
       "2696                  Theory  False           4  \n",
       "2699   Probabilistic_Methods  False           3  \n",
       "2702      Genetic_Algorithms  False           5  \n",
       "2703      Genetic_Algorithms  False           5  \n",
       "2704      Genetic_Algorithms  False           5  \n",
       "2705      Genetic_Algorithms  False           5  \n",
       "2706              Case_Based  False           6  \n",
       "2707         Neural_Networks   True           0  \n",
       "\n",
       "[2485 rows x 1437 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "contents['is_ml'] = contents['label'].isin(['Neural_Networks','Reinforcement_Learning','Genetic_Algorithms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y = contents['num_labels']\n",
    "y = contents['is_ml']\n",
    "X = contents.drop(['id','is_nn','is_rl','is_ga','is_theory','is_ml','label','num_labels'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=15)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 15)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pca_contents = pd.DataFrame(data=np.hstack((y.reshape(2485,1),X_pca)),\n",
    "                   columns = [\"label\"] + ['feature_'+str(i) for i in range(X_pca.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_contents.to_csv('../cora/pca_contents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2485, 1433)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2485, 129)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "lrcv = LogisticRegressionCV(penalty=\"l1\",solver='liblinear').fit(X, y)\n",
    "model = SelectFromModel(lrcv, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 22)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrcv_new = LogisticRegression(C=0.05,penalty=\"l1\",solver='liblinear').fit(X, y)\n",
    "# lrcv_new = LogisticRegression(C=0.02,penalty=\"l1\",solver='liblinear').fit(X, y)\n",
    "model_new = SelectFromModel(lrcv_new, prefit=True)\n",
    "X_new_new = model_new.transform(X)\n",
    "X_new_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "selected_contents = pd.DataFrame(data=np.hstack((y.reshape(2485,1),X_new_new)),\n",
    "                   columns = [\"label\"] + ['feature_'+str(i) for i in range(X_new_new.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_contents.to_csv('../cora/selected_contents_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 20)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_contents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = np.loadtxt(node_dir,delimiter=',')\n",
    "edges = pd.read_csv(edge_dir)\n",
    "# graph = np.loadtxt(graph_dir,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_nodes = pd.read_csv(all_node_dir,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fill_NaN = Imputer(missing_values=np.nan, strategy='mean', axis=0)\n",
    "all_nodes = pd.DataFrame(fill_NaN.fit_transform(all_nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12187484.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093935</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>0.019375</td>\n",
       "      <td>0.063161</td>\n",
       "      <td>0.170891</td>\n",
       "      <td>0.067702</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2344352.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023618</td>\n",
       "      <td>0.014784</td>\n",
       "      <td>0.030926</td>\n",
       "      <td>0.052232</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>0.038493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14654069.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102263</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>0.044636</td>\n",
       "      <td>0.022996</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>0.018277</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16443886.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.038715</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>0.023996</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.022571</td>\n",
       "      <td>0.006989</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2684155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030616</td>\n",
       "      <td>0.080179</td>\n",
       "      <td>0.019288</td>\n",
       "      <td>0.057942</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15032912.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116897</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.021041</td>\n",
       "      <td>0.039660</td>\n",
       "      <td>0.074813</td>\n",
       "      <td>0.022330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17988185.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.017365</td>\n",
       "      <td>0.032801</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9834350.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>0.026710</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.020420</td>\n",
       "      <td>0.036443</td>\n",
       "      <td>0.025869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16230722.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.010479</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.031140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3542527.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.027970</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.072825</td>\n",
       "      <td>0.070745</td>\n",
       "      <td>0.074849</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.032999</td>\n",
       "      <td>0.066351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10960717.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103328</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.051553</td>\n",
       "      <td>0.043113</td>\n",
       "      <td>0.065184</td>\n",
       "      <td>0.067006</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15723700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017411</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.025662</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.024929</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16118269.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.097250</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>0.020059</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0.020857</td>\n",
       "      <td>0.012253</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8293860.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.045128</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>0.013315</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17039422.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.068214</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10492318.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.011790</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>0.069488</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.010282</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.018870</td>\n",
       "      <td>0.058568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7152132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.174583</td>\n",
       "      <td>0.017292</td>\n",
       "      <td>0.037343</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.051913</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8104271.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017398</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.013355</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.020488</td>\n",
       "      <td>0.037863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17764005.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>0.025489</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.025569</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17914032.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.010682</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.017084</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12112937.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.027752</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.029610</td>\n",
       "      <td>0.028006</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.040198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11756346.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>0.022101</td>\n",
       "      <td>0.019948</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.024808</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11731221.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.060981</td>\n",
       "      <td>0.077702</td>\n",
       "      <td>0.030044</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.029147</td>\n",
       "      <td>0.042555</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10218793.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068886</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>0.051553</td>\n",
       "      <td>0.027856</td>\n",
       "      <td>0.036935</td>\n",
       "      <td>0.047492</td>\n",
       "      <td>0.051434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7567975.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.031643</td>\n",
       "      <td>0.135371</td>\n",
       "      <td>0.058342</td>\n",
       "      <td>0.069809</td>\n",
       "      <td>0.063683</td>\n",
       "      <td>0.040883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16306557.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.046934</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9682700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.160172</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.053956</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9356032.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.010290</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10613759.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009763</td>\n",
       "      <td>0.028103</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.025895</td>\n",
       "      <td>0.060170</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16219016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.019310</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.017767</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19687</th>\n",
       "      <td>17392166.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>0.144128</td>\n",
       "      <td>0.008154</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.025824</td>\n",
       "      <td>0.019916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19688</th>\n",
       "      <td>17047293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.201616</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.043240</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.050474</td>\n",
       "      <td>0.052298</td>\n",
       "      <td>0.038890</td>\n",
       "      <td>0.037647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19689</th>\n",
       "      <td>10323602.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>0.021137</td>\n",
       "      <td>0.020378</td>\n",
       "      <td>0.020808</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>0.030460</td>\n",
       "      <td>0.030015</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19690</th>\n",
       "      <td>17284223.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>0.035656</td>\n",
       "      <td>0.023638</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>0.016876</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0.062231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19691</th>\n",
       "      <td>17353295.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.015601</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.007861</td>\n",
       "      <td>0.032050</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19692</th>\n",
       "      <td>11748649.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>0.016714</td>\n",
       "      <td>0.133319</td>\n",
       "      <td>0.025868</td>\n",
       "      <td>0.039863</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.023888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19693</th>\n",
       "      <td>8616951.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19694</th>\n",
       "      <td>11874930.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.047581</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>0.027744</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>0.024646</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19695</th>\n",
       "      <td>17439741.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>0.022886</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.043587</td>\n",
       "      <td>0.049368</td>\n",
       "      <td>0.107097</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19696</th>\n",
       "      <td>12023947.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053910</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.019270</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>0.022494</td>\n",
       "      <td>0.190648</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>0.322661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19697</th>\n",
       "      <td>8314020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.014080</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19698</th>\n",
       "      <td>7711537.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.027102</td>\n",
       "      <td>0.029995</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>0.014107</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>0.014611</td>\n",
       "      <td>0.023113</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19699</th>\n",
       "      <td>16368054.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19700</th>\n",
       "      <td>19490620.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.019577</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.028067</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19701</th>\n",
       "      <td>8039607.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.026477</td>\n",
       "      <td>0.084479</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.022571</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.021888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19702</th>\n",
       "      <td>17062758.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.016619</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.029239</td>\n",
       "      <td>0.048557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19703</th>\n",
       "      <td>11086048.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.123063</td>\n",
       "      <td>0.039797</td>\n",
       "      <td>0.038612</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.056684</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>0.024342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19704</th>\n",
       "      <td>9745032.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.187870</td>\n",
       "      <td>0.038751</td>\n",
       "      <td>0.049201</td>\n",
       "      <td>0.041794</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.040292</td>\n",
       "      <td>0.061240</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19705</th>\n",
       "      <td>6782822.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111426</td>\n",
       "      <td>0.131798</td>\n",
       "      <td>0.245759</td>\n",
       "      <td>0.451960</td>\n",
       "      <td>0.265606</td>\n",
       "      <td>0.187578</td>\n",
       "      <td>0.238026</td>\n",
       "      <td>0.194391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19706</th>\n",
       "      <td>276854.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.075959</td>\n",
       "      <td>0.082338</td>\n",
       "      <td>0.493148</td>\n",
       "      <td>0.011648</td>\n",
       "      <td>0.099784</td>\n",
       "      <td>0.107339</td>\n",
       "      <td>0.045813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19707</th>\n",
       "      <td>6714535.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071881</td>\n",
       "      <td>0.047062</td>\n",
       "      <td>0.039742</td>\n",
       "      <td>0.107341</td>\n",
       "      <td>0.046613</td>\n",
       "      <td>0.030102</td>\n",
       "      <td>0.014433</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19708</th>\n",
       "      <td>1727730.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.091746</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.018888</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19709</th>\n",
       "      <td>3311856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.012894</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>0.092624</td>\n",
       "      <td>0.158662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19710</th>\n",
       "      <td>17508911.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.023681</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.030067</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>0.148132</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.021728</td>\n",
       "      <td>0.059561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19711</th>\n",
       "      <td>2185105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.017564</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.017407</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19712</th>\n",
       "      <td>17559889.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.022998</td>\n",
       "      <td>0.022886</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.029714</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>0.067142</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.034947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19713</th>\n",
       "      <td>8792097.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.030048</td>\n",
       "      <td>0.011253</td>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.109661</td>\n",
       "      <td>0.024979</td>\n",
       "      <td>0.066637</td>\n",
       "      <td>0.020805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19714</th>\n",
       "      <td>17934141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067942</td>\n",
       "      <td>0.014177</td>\n",
       "      <td>0.059311</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>0.061112</td>\n",
       "      <td>0.018317</td>\n",
       "      <td>0.024286</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19715</th>\n",
       "      <td>18673544.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>0.027898</td>\n",
       "      <td>0.011369</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.010110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19716</th>\n",
       "      <td>18564175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.175050</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.050937</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>0.014198</td>\n",
       "      <td>0.024507</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.033084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19717 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1         2         3         4         5         6    \\\n",
       "0      12187484.0  1.0  0.093935  0.028698  0.011760  0.019375  0.063161   \n",
       "1       2344352.0  1.0  0.023618  0.014784  0.030926  0.052232  0.025327   \n",
       "2      14654069.0  1.0  0.102263  0.010669  0.044636  0.022996  0.013785   \n",
       "3      16443886.0  2.0  0.038715  0.014075  0.023996  0.013403  0.022571   \n",
       "4       2684155.0  1.0  0.030616  0.080179  0.019288  0.057942  0.019854   \n",
       "5      15032912.0  1.0  0.116897  0.005201  0.018466  0.012191  0.021041   \n",
       "6      17988185.0  3.0  0.007445  0.011114  0.013230  0.017365  0.032801   \n",
       "7       9834350.0  3.0  0.006157  0.031884  0.026710  0.010940  0.007875   \n",
       "8      16230722.0  3.0  0.010479  0.004294  0.004273  0.020031  0.004322   \n",
       "9       3542527.0  2.0  0.027970  0.013917  0.072825  0.070745  0.074849   \n",
       "10     10960717.0  1.0  0.103328  0.035522  0.038086  0.051553  0.043113   \n",
       "11     15723700.0  3.0  0.017411  0.005747  0.009919  0.025662  0.012127   \n",
       "12     16118269.0  1.0  0.097250  0.024350  0.020059  0.006058  0.025469   \n",
       "13      8293860.0  3.0  0.004951  0.023209  0.045128  0.021256  0.026633   \n",
       "14     17039422.0  3.0  0.008999  0.068214  0.011072  0.011381  0.009323   \n",
       "15     10492318.0  2.0  0.011790  0.020469  0.069488  0.006147  0.010282   \n",
       "16      7152132.0  1.0  0.016611  0.174583  0.017292  0.037343  0.017911   \n",
       "17      8104271.0  3.0  0.017398  0.018654  0.006157  0.010628  0.013355   \n",
       "18     17764005.0  3.0  0.026311  0.025489  0.008728  0.030985  0.020971   \n",
       "19     17914032.0  3.0  0.024756  0.011690  0.010682  0.006530  0.020135   \n",
       "20     12112937.0  2.0  0.027752  0.005659  0.029610  0.028006  0.015217   \n",
       "21     11756346.0  3.0  0.025534  0.022101  0.019948  0.006378  0.018355   \n",
       "22     11731221.0  3.0  0.023285  0.060981  0.077702  0.030044  0.016998   \n",
       "23     10218793.0  1.0  0.068886  0.021560  0.045101  0.051553  0.027856   \n",
       "24      7567975.0  2.0  0.025872  0.032719  0.031643  0.135371  0.058342   \n",
       "25     16306557.0  3.0  0.011443  0.019698  0.046934  0.011573  0.014148   \n",
       "26      9682700.0  2.0  0.160172  0.006094  0.014642  0.015824  0.007141   \n",
       "27      9356032.0  3.0  0.016836  0.011367  0.016092  0.008725  0.014295   \n",
       "28     10613759.0  1.0  0.009763  0.028103  0.004858  0.011386  0.019523   \n",
       "29     16219016.0  3.0  0.016558  0.008239  0.019310  0.008332  0.010186   \n",
       "...           ...  ...       ...       ...       ...       ...       ...   \n",
       "19687  17392166.0  3.0  0.030143  0.144128  0.008154  0.030806  0.014075   \n",
       "19688  17047293.0  1.0  0.201616  0.012559  0.043240  0.025403  0.050474   \n",
       "19689  10323602.0  3.0  0.095015  0.021137  0.020378  0.020808  0.012764   \n",
       "19690  17284223.0  2.0  0.013732  0.035656  0.023638  0.013887  0.013341   \n",
       "19691  17353295.0  3.0  0.015601  0.002588  0.006719  0.006065  0.007861   \n",
       "19692  11748649.0  1.0  0.012936  0.012873  0.016714  0.133319  0.025868   \n",
       "19693   8616951.0  3.0  0.012954  0.013101  0.008709  0.004176  0.014561   \n",
       "19694  11874930.0  3.0  0.047581  0.019598  0.011838  0.027744  0.014636   \n",
       "19695  17439741.0  1.0  0.013891  0.022886  0.006912  0.043587  0.049368   \n",
       "19696  12023947.0  1.0  0.053910  0.011194  0.019270  0.006559  0.022494   \n",
       "19697   8314020.0  2.0  0.017180  0.014080  0.009096  0.012315  0.014171   \n",
       "19698   7711537.0  2.0  0.027102  0.029995  0.013704  0.014107  0.008736   \n",
       "19699  16368054.0  3.0  0.009950  0.008565  0.017491  0.010063  0.006151   \n",
       "19700  19490620.0  3.0  0.019577  0.021543  0.003992  0.017291  0.010365   \n",
       "19701   8039607.0  1.0  0.016882  0.005098  0.026477  0.084479  0.005975   \n",
       "19702  17062758.0  3.0  0.009408  0.023406  0.016619  0.010971  0.020724   \n",
       "19703  11086048.0  2.0  0.025714  0.123063  0.039797  0.038612  0.012768   \n",
       "19704   9745032.0  3.0  0.187870  0.038751  0.049201  0.041794  0.030389   \n",
       "19705   6782822.0  1.0  0.111426  0.131798  0.245759  0.451960  0.265606   \n",
       "19706    276854.0  1.0  0.029004  0.075959  0.082338  0.493148  0.011648   \n",
       "19707   6714535.0  1.0  0.071881  0.047062  0.039742  0.107341  0.046613   \n",
       "19708   1727730.0  2.0  0.011128  0.032031  0.005537  0.014378  0.091746   \n",
       "19709   3311856.0  3.0  0.010630  0.012894  0.003488  0.006020  0.018086   \n",
       "19710  17508911.0  2.0  0.023681  0.007152  0.030067  0.025541  0.148132   \n",
       "19711   2185105.0  2.0  0.013425  0.014395  0.017564  0.009503  0.021217   \n",
       "19712  17559889.0  3.0  0.022998  0.022886  0.040625  0.029714  0.013410   \n",
       "19713   8792097.0  2.0  0.008728  0.030048  0.011253  0.032390  0.109661   \n",
       "19714  17934141.0  1.0  0.067942  0.014177  0.059311  0.025043  0.061112   \n",
       "19715  18673544.0  3.0  0.009240  0.009195  0.011938  0.016163  0.027898   \n",
       "19716  18564175.0  3.0  0.175050  0.006058  0.050937  0.043269  0.014198   \n",
       "\n",
       "            7         8         9      ...          114       115       116  \\\n",
       "0      0.170891  0.067702  0.017555    ...     0.022972  0.015343  0.030595   \n",
       "1      0.008620  0.014879  0.038493    ...     0.022972  0.015343  0.030595   \n",
       "2      0.018277  0.006221  0.010738    ...     0.022972  0.015343  0.030595   \n",
       "3      0.006989  0.011919  0.021452    ...     0.022972  0.015343  0.030595   \n",
       "4      0.012295  0.014292  0.020564    ...     0.022972  0.015343  0.030595   \n",
       "5      0.039660  0.074813  0.022330    ...     0.022972  0.015343  0.030595   \n",
       "6      0.009160  0.015904  0.007713    ...     0.022972  0.015343  0.030595   \n",
       "7      0.020420  0.036443  0.025869    ...     0.022972  0.015343  0.030595   \n",
       "8      0.038014  0.010244  0.031140    ...     0.022972  0.015343  0.030595   \n",
       "9      0.017944  0.032999  0.066351    ...     0.022972  0.015343  0.030595   \n",
       "10     0.065184  0.067006  0.013832    ...     0.022972  0.015343  0.030595   \n",
       "11     0.024929  0.013188  0.006323    ...     0.022972  0.015343  0.030595   \n",
       "12     0.020857  0.012253  0.025226    ...     0.022972  0.015343  0.030595   \n",
       "13     0.013315  0.006384  0.010677    ...     0.022972  0.015343  0.030595   \n",
       "14     0.005773  0.006711  0.019312    ...     0.022972  0.015343  0.030595   \n",
       "15     0.010484  0.018870  0.058568    ...     0.022972  0.015343  0.030595   \n",
       "16     0.051913  0.029500  0.034562    ...     0.022972  0.015343  0.030595   \n",
       "17     0.010940  0.020488  0.037863    ...     0.022972  0.015343  0.030595   \n",
       "18     0.025569  0.010791  0.009086    ...     0.022972  0.015343  0.030595   \n",
       "19     0.003405  0.017084  0.005807    ...     0.022972  0.015343  0.030595   \n",
       "20     0.029976  0.021000  0.040198    ...     0.022972  0.015343  0.030595   \n",
       "21     0.024808  0.011806  0.020921    ...     0.022972  0.015343  0.030595   \n",
       "22     0.029147  0.042555  0.015100    ...     0.022972  0.015343  0.030595   \n",
       "23     0.036935  0.047492  0.051434    ...     0.022972  0.015343  0.030595   \n",
       "24     0.069809  0.063683  0.040883    ...     0.022972  0.015343  0.030595   \n",
       "25     0.014542  0.007377  0.017881    ...     0.022972  0.015343  0.030595   \n",
       "26     0.053956  0.006163  0.007534    ...     0.022972  0.015343  0.030595   \n",
       "27     0.010630  0.010290  0.014806    ...     0.022972  0.015343  0.030595   \n",
       "28     0.025895  0.060170  0.006263    ...     0.022972  0.015343  0.030595   \n",
       "29     0.010623  0.017767  0.025749    ...     0.022972  0.015343  0.030595   \n",
       "...         ...       ...       ...    ...          ...       ...       ...   \n",
       "19687  0.017686  0.025824  0.019916    ...     0.022972  0.015343  0.030595   \n",
       "19688  0.052298  0.038890  0.037647    ...     0.022972  0.015343  0.030595   \n",
       "19689  0.030460  0.030015  0.033473    ...     0.022972  0.015343  0.030595   \n",
       "19690  0.016876  0.016877  0.062231    ...     0.022972  0.015343  0.030595   \n",
       "19691  0.032050  0.008087  0.003589    ...     0.022972  0.015343  0.030595   \n",
       "19692  0.039863  0.009647  0.023888    ...     0.022972  0.015343  0.030595   \n",
       "19693  0.012817  0.011503  0.031465    ...     0.022972  0.015343  0.030595   \n",
       "19694  0.024646  0.015916  0.007631    ...     0.022972  0.015343  0.030595   \n",
       "19695  0.107097  0.006990  0.008546    ...     0.022972  0.015343  0.030595   \n",
       "19696  0.190648  0.021824  0.322661    ...     0.022972  0.015343  0.030595   \n",
       "19697  0.008903  0.030077  0.007293    ...     0.022972  0.015343  0.030595   \n",
       "19698  0.014611  0.023113  0.020807    ...     0.022972  0.015343  0.030595   \n",
       "19699  0.006323  0.010358  0.003207    ...     0.022972  0.015343  0.030595   \n",
       "19700  0.013743  0.028067  0.008074    ...     0.022972  0.015343  0.030595   \n",
       "19701  0.022571  0.040979  0.021888    ...     0.022972  0.015343  0.030595   \n",
       "19702  0.020097  0.029239  0.048557    ...     0.022972  0.015343  0.030595   \n",
       "19703  0.056684  0.012170  0.024342    ...     0.022972  0.015343  0.030595   \n",
       "19704  0.040292  0.061240  0.014383    ...     0.022972  0.015343  0.030595   \n",
       "19705  0.187578  0.238026  0.194391    ...     0.022972  0.015343  0.030595   \n",
       "19706  0.099784  0.107339  0.045813    ...     0.022972  0.015343  0.030595   \n",
       "19707  0.030102  0.014433  0.016777    ...     0.022972  0.015343  0.030595   \n",
       "19708  0.007139  0.018888  0.012175    ...     0.022972  0.015343  0.030595   \n",
       "19709  0.029463  0.092624  0.158662    ...     0.022972  0.015343  0.030595   \n",
       "19710  0.008381  0.021728  0.059561    ...     0.022972  0.015343  0.030595   \n",
       "19711  0.012318  0.017407  0.025325    ...     0.022972  0.015343  0.030595   \n",
       "19712  0.067142  0.014064  0.034947    ...     0.022972  0.015343  0.030595   \n",
       "19713  0.024979  0.066637  0.020805    ...     0.022972  0.015343  0.030595   \n",
       "19714  0.018317  0.024286  0.014268    ...     0.022972  0.015343  0.030595   \n",
       "19715  0.011369  0.005928  0.010110    ...     0.022972  0.015343  0.030595   \n",
       "19716  0.024507  0.014980  0.033084    ...     0.022972  0.015343  0.030595   \n",
       "\n",
       "            117       118       119       120       121       122       123  \n",
       "0      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "1      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "2      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "3      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "4      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "5      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "6      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "7      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "8      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "9      0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "10     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "11     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "12     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "13     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "14     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "15     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "16     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "17     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "18     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "20     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "21     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "22     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "23     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "24     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "25     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "26     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "27     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "28     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "29     0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "19687  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19688  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19689  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19690  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19691  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19692  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19693  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19694  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19695  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19696  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19697  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19698  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19699  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19700  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19701  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19702  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19703  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19704  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19705  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19706  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19707  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19708  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19709  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19710  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19711  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19712  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19713  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19714  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19715  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "19716  0.011753  0.017246  0.036326  0.030719  0.035853  0.022927  0.013428  \n",
       "\n",
       "[19717 rows x 124 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (all_nodes[1] > 1).as_matrix().astype(int)\n",
    "X = all_nodes.iloc[:,2:].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19717, 122)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "X.shape\n",
    "\n",
    "lrcv = LogisticRegressionCV(penalty=\"l1\",solver='liblinear').fit(X, y)\n",
    "model = SelectFromModel(lrcv, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19717, 8)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X.shape\n",
    "\n",
    "lrcv_new = LogisticRegression(C=0.1,penalty=\"l1\",solver='liblinear').fit(X, y)\n",
    "model_new = SelectFromModel(lrcv_new, prefit=True)\n",
    "X_new_new = model_new.transform(X)\n",
    "X_new_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = np.hstack((all_nodes[0].as_matrix().reshape(19717,1),y.reshape(19717,1),X_new_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19717,), (19717,), (19717, 8))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes[0].as_matrix().shape,y.shape,X_new_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('nodes_selected.csv',out,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80958418,  0.81490872,  0.80831643,  0.82120213,  0.81278539])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(C=0.1,penalty=\"l1\",solver='liblinear'), X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv.scores_[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10000.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.821031806422\n"
     ]
    }
   ],
   "source": [
    "print ('Max:', lrcv.scores_[1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of the ragularization param with the best performance: 10000.0\n"
     ]
    }
   ],
   "source": [
    "print('Inverse of the ragularization param with the best performance:',lrcv.C_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.046416</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>166.810054</td>\n",
       "      <td>1291.549665</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.208124</td>\n",
       "      <td>0.791876</td>\n",
       "      <td>0.791876</td>\n",
       "      <td>0.806937</td>\n",
       "      <td>0.815305</td>\n",
       "      <td>0.816218</td>\n",
       "      <td>0.816066</td>\n",
       "      <td>0.816066</td>\n",
       "      <td>0.816066</td>\n",
       "      <td>0.816066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5          6  \\\n",
       "0  0.000100  0.000774  0.005995  0.046416  0.359381  2.782559  21.544347   \n",
       "1  0.208124  0.791876  0.791876  0.806937  0.815305  0.816218   0.816066   \n",
       "\n",
       "            7            8             9  \n",
       "0  166.810054  1291.549665  10000.000000  \n",
       "1    0.816066     0.816066      0.816066  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=lrcv.Cs_\n",
    "b=lrcv.scores_[1][0]\n",
    "pd.DataFrame(np.vstack((a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-234e62c1996a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m scores = cross_val_score(\n\u001b[0;32m----> 4\u001b[0;31m     lrcv, X, y, cv=10)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             return_times=True)\n\u001b[0;32m--> 195\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1685\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m                       )\n\u001b[0;32m-> 1687\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m             for train, test in folds)\n\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(\n",
    "    lrcv, X, y, cv=10)\n",
    "scores     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.21874840e+07,   1.00000000e+00,   9.39348960e-02, ...,\n",
       "          6.77024800e-02,   1.75546100e-02,   9.84015120e-02],\n",
       "       [  2.34435200e+06,   1.00000000e+00,   2.36179170e-02, ...,\n",
       "          1.48791710e-02,   3.84934380e-02,   1.81900310e-02],\n",
       "       [  1.46540690e+07,   1.00000000e+00,   1.02263144e-01, ...,\n",
       "          6.22094900e-03,   1.07375460e-02,   9.34449450e-02],\n",
       "       ..., \n",
       "       [  1.79341410e+07,   1.00000000e+00,   6.79419520e-02, ...,\n",
       "          2.42857410e-02,   1.42676980e-02,   1.74424950e-02],\n",
       "       [  1.86735440e+07,   3.00000000e+00,   9.24009900e-03, ...,\n",
       "          5.92790100e-03,   1.01097040e-02,   1.44419330e-02],\n",
       "       [  1.85641750e+07,   3.00000000e+00,   1.75050441e-01, ...,\n",
       "          1.49800250e-02,   3.30840700e-02,   7.81088100e-03]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-e568145143cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mUy_lp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mUy_lp_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mUy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "lp = LP()\n",
    "Uy_lp = np.rint(lp.closed(features,Ly))\n",
    "Uy_lp_iter = np.rint(lp.iter_(features,Ly,Uy,1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
